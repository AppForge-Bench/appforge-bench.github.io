{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AppForge \u2014 Benchmarking LLMs for Android App Generation","text":"<p>A benchmark to evaluate large language models on generating runnable Android apps from task specs.</p> <p>AppForge provides:</p> <ul> <li>\u2705 Real-world Android tasks (UI &amp; functionality)</li> <li>\u2705 Reproducible evaluation harness (Docker + Gradle)</li> <li>\u2705 Multiple dataset splits (Base, Lite, Verified)</li> <li>\u2705 Leaderboards and baselines</li> </ul> <p>:material-rocket-launch: Get started in minutes \u2014 see the Quick Start below.</p>"},{"location":"#quick-start","title":"Quick Start","text":"pipDocker <pre><code>pip install mkdocs-material\nmkdocs serve\n</code></pre> <pre><code>docker run --rm -it -p 8000:8000 -v ${PWD}:/docs squidfunk/mkdocs-material\n</code></pre>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<ul> <li>Getting Started \u2014 install, run the harness, and evaluate a model.</li> <li>User Guides \u2014 datasets, evaluation protocol, examples.</li> <li>Reference \u2014 CLI/API for the harness.</li> <li>Leaderboard \u2014 sortable table of results.</li> <li>Cite \u2014 how to reference this benchmark.</li> </ul>"},{"location":"api/","title":"API / CLI","text":"<pre><code>appforge eval --model &lt;id&gt; --task &lt;split&gt; --out &lt;file.json&gt;\nappforge score --pred &lt;file.json&gt; --gold &lt;gold.json&gt;\n</code></pre>"},{"location":"cite/","title":"Citation","text":"<pre><code>@inproceedings{appforge2025,\n  title={{AppForge}: Evaluating LLMs for Android App Generation},\n  author={Your Name and Team},\n  booktitle={Your Venue},\n  year={2025}\n}\n</code></pre>"},{"location":"datasets/","title":"Datasets","text":"<ul> <li>AppForge Base \u2014 ~1k tasks curated from real apps.</li> <li>AppForge Lite \u2014 small split for quick experiments.</li> <li>AppForge Verified \u2014 tasks validated by human engineers.</li> </ul>"},{"location":"datasets/#format","title":"Format","text":"<p>Each task provides: - <code>task_id</code>, <code>spec</code> (instruction + constraints), <code>assets</code> (optional), <code>checks</code> (expected behaviors).</p>"},{"location":"datasets/#access","title":"Access","text":"<ul> <li>Download links (TBD)</li> <li>SHA256 checksums</li> </ul>"},{"location":"datasets/#license-ethics","title":"License &amp; Ethics","text":"<ul> <li>Include license and any privacy/safety considerations.</li> </ul>"},{"location":"evaluation/","title":"Evaluation","text":"<p>This section explains the evaluation harness, metrics, and configuration.</p>"},{"location":"evaluation/#metrics","title":"Metrics","text":"<ul> <li>Pass@1 \u2014 whether the generated app passes all task checks on the first try.</li> <li>Build success \u2014 Gradle build without errors.</li> <li>Runtime checks \u2014 instrumentation tests &amp; UI smoke tests.</li> <li>Time \u2014 average generation + build time per task.</li> </ul>"},{"location":"evaluation/#task-pipeline","title":"Task pipeline","text":"<ol> <li>Parse task</li> <li>Model generate (code + resources)</li> <li>Gradle build</li> <li>Install on emulator</li> <li>Run tests/checkers</li> <li>Record logs and scores</li> </ol>"},{"location":"evaluation/#reproducibility","title":"Reproducibility","text":"<ul> <li>Pin model version, dataset commit, Docker image, and seed.</li> <li>Save CLI command to <code>command.txt</code>, env info to <code>env.txt</code>, and raw outputs (<code>results.json</code>, logs/).</li> </ul>"},{"location":"faq/","title":"FAQ","text":"<p>Q: How do I reproduce a run? A: Pin your model version, Docker image, and dataset commit hash. Provide the command line you used.</p> <p>Q: Build fails? A: Check Android SDK and Build Tools versions, Gradle cache, and network. See <code>logs/build.log</code>.</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#requirements","title":"Requirements","text":"<ul> <li>Python 3.9+</li> <li>Docker (20.10+) and Docker Compose</li> <li>Java 17 (for Android builds)</li> <li>Android SDK (commandline-tools + build-tools)</li> </ul>"},{"location":"getting-started/#install-placeholder-repo","title":"Install (placeholder repo)","text":"<pre><code>git clone YOUR_REPO_URL appforge\ncd appforge\npip install -e .\n</code></pre>"},{"location":"getting-started/#evaluate-a-model","title":"Evaluate a model","text":"<pre><code>appforge eval --model gpt-xxx --task lite --out results/run_001.json\n</code></pre>"},{"location":"getting-started/#local-docs","title":"Local docs","text":"<pre><code>pip install mkdocs-material\nmkdocs serve\n</code></pre>"},{"location":"leaderboard/","title":"Leaderboard","text":"<p>Click a column to sort.</p> Model Version Pass@1 (%) Build success (%) APK size (MB) Avg gen time (s) Eval date Eval protocol GPT-5-Android 2025-07 62.5 81.0 23.4 138 2025-08-01 v1.0 DeepSeek-AndroidXL 2025-06 58.1 77.2 24.8 151 2025-07-28 v1.0 Claude-Next-Mobile 2025-06 55.7 79.3 22.9 160 2025-07-20 v1.0 Llama-4.1-Code 2025-07 47.9 70.6 26.3 172 2025-07-18 v1.0"}]}